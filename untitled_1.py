# -*- coding: utf-8 -*-
"""Untitled-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wk5JtRcY7APviy9sdee26BayE-5oWcrV
"""

! pip install chembl_webresource_client

! pip install rdkit

! pip install bash --upgrade



from chembl_webresource_client.new_client import new_client
import pandas as pd
import numpy as np
import sys
sys.path.append('/usr/local/lib/python3.10.5/site-packages/')

from rdkit import Chem
from rdkit.Chem import Descriptors, Lipinski

tg = input("target of interest : ")
org = input("organism of interest : ")

# Target search for coronavirus
target = new_client.target
target_query = target.search(tg)
targets = pd.DataFrame.from_dict(target_query)
selected_target = targets.target_chembl_id[3]
activity = new_client.activity
res = activity.filter(target_chembl_id=selected_target).filter(standard_type='IC50')
df = pd.DataFrame.from_dict(res)

df2 = df[df.standard_value.notna() & df.canonical_smiles.notna()]
df2_nr = df2.drop_duplicates(['canonical_smiles'])

selection = ['molecule_chembl_id','canonical_smiles','standard_value' ]
df3 = df2_nr[selection]

df3.to_csv(tg+'_02_bioactivity_data_preprocessed.csv', index=False)

df4 = pd.read_csv(tg+'_02_bioactivity_data_preprocessed.csv')

bioactivity_threshold = []
for i in df4.standard_value:
  if float(i) >= 10000:
    bioactivity_threshold.append("inactive")
  elif float(i) <= 1000:
    bioactivity_threshold.append("active")
  else:
    bioactivity_threshold.append("intermediate")

mol_cid = []
for i in df4.molecule_chembl_id:
  mol_cid.append(i)

canonical_smiles = []
for i in df4.canonical_smiles:
  canonical_smiles.append(i)
  
standard_value = []
for i in df4.standard_value:
  standard_value.append(i)

selection = ['molecule_chembl_id', 'canonical_smiles', 'standard_value']
df4[selection]

df4.to_csv(tg + '_03_bioactivity_data_preprocessed.csv', index=False)

df5 = pd.read_csv('mTOR_03_bioactivity_data_preprocessed.csv')

bioactivity_class = pd.Series(bioactivity_threshold, name='class')
df5 = pd.concat([df4, bioactivity_class], axis=1)

df_no_smiles = df5.drop(columns='canonical_smiles')

smiles = []

for i in df5.canonical_smiles.tolist():
  cpd = str(i).split('.')
  cpd_longest = max(cpd, key = len)
  smiles.append(cpd_longest)

# Inspired by: https://codeocean.com/explore/capsules?query=tag:data-curation

def lipinski(smiles, verbose=False):

    moldata= []
    for elem in smiles:
        mol=Chem.MolFromSmiles(elem) 
        moldata.append(mol)
       
    baseData= np.arange(1,1)
    i=0  
    for mol in moldata:        
       
        desc_MolWt = Descriptors.MolWt(mol)
        desc_MolLogP = Descriptors.MolLogP(mol)
        desc_NumHDonors = Lipinski.NumHDonors(mol)
        desc_NumHAcceptors = Lipinski.NumHAcceptors(mol)
           
        row = np.array([desc_MolWt,
                        desc_MolLogP,
                        desc_NumHDonors,
                        desc_NumHAcceptors])   
    
        if(i==0):
            baseData=row
        else:
            baseData=np.vstack([baseData, row])
        i=i+1      
    
    columnNames=["MW","LogP","NumHDonors","NumHAcceptors"]   
    descriptors = pd.DataFrame(data=baseData,columns=columnNames)
    
    return descriptors

def pIC50(input):
    pIC50 = []

    for i in input['standard_value_norm']:
        molar = i*(10**-9) # Converts nM to M
        pIC50.append(-np.log10(molar))

    input['pIC50'] = pIC50
    x = input.drop('standard_value_norm', axis=1)
        
    return x

def norm_value(input):
    norm = []

    for i in input['standard_value']:
        if i > 100000000:
          i = 100000000
        norm.append(i)

    input['standard_value_norm'] = norm
    x = input.drop('standard_value', axis=1)
        
    return x

smiles = pd.Series(smiles, name = 'canonical_smiles')
df_clean_smiles = pd.concat([df_no_smiles,smiles], axis=1)
df_lipinski = lipinski(df_clean_smiles.canonical_smiles)

df_combined = pd.concat([df5,df_lipinski], axis=1)
df_norm = norm_value(df_combined)
df_final = pIC50(df_norm)

import wget

url1 = 'https://github.com/dataprofessor/bioinformatics/raw/master/padel.zip'
wget.download(url1)
url2 = 'https://github.com/dataprofessor/bioinformatics/raw/master/padel.sh'
wget.download(url2)

from zipfile import ZipFile
zip = ZipFile('padel.zip')
zip.extractall()

selection = ['canonical_smiles','molecule_chembl_id']
df3_selection = df_final[selection]
df3_selection.to_csv('molecule.smi', sep='\t', index=False, header=False)

! type padel.sh

from bash import bash

bash('padel.sh')

df3_X = pd.read_csv('descriptors_output.csv')

